---
layout: post
title: "How to master an ANOVA: Examples in Python and R"
---

In [one of my previous blog posts](https://nicoleeic.github.io/2019/09/01/Hypothesis_tests.html) I talked about how to pick the right statistical hypothesis test for your experimental design. One of the most heavily used family of tests for psychological and in general for experimental research is Analysis of Variance (ANOVA). Most analysis frameworks have build-in implementations for ANOVAs -- with different strengths and limitations. But in order to set up and interpret your ANOVA correctly, it is necessary to understand it in the more general context of linear models and linear regression.

Here, I wrote a tutorial of how to conduct an ANOVA in Python and R and how to assess the underlying models matrices. Note that I didn't include the assumption checks or post-hoc tests that you would typically want to do. Furthermore, the examples below include 3 and 4-factorial ANOVAs to demonstrate the underlying principles, but in practice you might want to break down your design. Such 'big' ANOVAs are not recommended, because they don't account for the multiple tests involved. The code for the examples below can be found [in my Github repository](https://github.com/NicoleEic/projects/tree/master/neuro_scripts/GLM_demo).

The imports that I used for all Python code below are the following:
```
import os
import random
import numpy as np
import pandas as pd
import patsy
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.stats.anova import AnovaRM
from scipy import stats
import seaborn as sns
```
___
# 1-way ANOVA in Python (between-subject factor)
___
Let's start with an example, where we are comparing an outcome measure in three different groups of subjects (healthy controls and two groups of patients, 10 subjects per group). Here, I'm simulating data with an effect of group and plot the data to inspect it.
```
# information on experimental design
group_list = ['control','patient1','patient2']
subs_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']

# read data into dataframe
df_1way = pd.DataFrame(columns=["group", "my_value"])
my_row = 0
for ind_g, group in enumerate(group_list):
    for sub in subs_list:
        # generate random value here as example
        my_val = np.random.normal(ind_g, 1, 1)[0]
        df_1way.loc[my_row] = [group, my_val]
        my_row = my_row + 1

# inspect data
sns.catplot(x="group", y="my_value", data=df_1way, dodge=True, kind='violin', aspect=3)
plt.show()
```

In order to conduct an ANOVA, we need to need to perform three steps: 1) Generate a model that fits our design, 2) Fit our data to the model to obtain the parameter estimates, 3) Derive the statistics using a summary function of the model fit. In Python, these steps are implemented in the `statsmodels` library. The general function to perform a linear regression (which is underlying an ANOVA) is `ols`. You can specify your model for `ols` using the same formula syntax that is used in R. If you conduct a 1-way ANOVA, i.e. you only have one categorical factor in your design, you can also use the `f_oneway` function. If you run the code below, you will see that they give an identical result

```
# generate model for linear regression
my_model = smf.ols(formula='my_value ~ group', data=df_1way)

# fit model to data to obtain parameter estimates
my_model_fit = my_model.fit()

# print summary of linear regression
print(my_model_fit.summary())

# show anova table
anova_table = sm.stats.anova_lm(my_model_fit, typ=2)
print(anova_table)

# compare p-value to f_oneway analysis
F, p = stats.f_oneway(df_1way[df_1way['group'] == 'control'].my_value, df_1way[df_1way['group'] == 'patient1'].my_value, df_1way[df_1way['group'] == 'patient2'].my_value)
print(p)
```
___
# 2-way ANOVA in Python (between-subject factors)
___
In the next example, we are extending our design to include native language of the subjects as additional factor. This means that we are still in a fully between-subject design and each data point comes from a different subject. The function call to `ols` with the `*` operator will model both main effects for group and language and their interaction.
```
# information on experimental design
group_list = ['control','patient1','patient2']
language_list = ['English', 'German', 'French']
subs_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']

# read data into dataframe
df_2way = pd.DataFrame(columns=["group", "language", "my_value"])
my_row = 0
for ind_g, group in enumerate(group_list):
    for ind_l, lan in enumerate(language_list):
        for sub in subs_list:
                # generate random value here as example
                my_val = np.random.normal(ind_g + ind_l, 1, 1)[0]
                df_2way.loc[my_row] = [group, lan, my_val]
                my_row = my_row + 1


# plot data
sns.catplot(x="language", y="my_value", data=df_2way, dodge=True, hue='group', kind='violin', aspect=3)
plt.show()

# fit model to data to obtain parameter estimates
my_model_fit = smf.ols(formula='my_value ~ group * language', data=df_2way).fit()
# print summary of linear regression
print(my_model_fit.summary())
# show anova table
print(sm.stats.anova_lm(my_model_fit, typ=2))
```

## Patsy
At this point I would like to mention that `statsmodels` internally uses the `patsy` library to convert the specified formula to a model matrix. This is useful, because we can access and visualize the underlying model matrix. You can modify the design matrix, for example, to change the coding scheme for factorial categories from 'treatment' to 'sum' or use a different reference level.
```
# use Patsy to construct the model above
model_matrix = patsy.dmatrix("group * language", df_2way)
# visualize model
plt.show(plt.imshow(model_matrix, aspect='auto'))
# use sum coding scheme for factors
plt.show(plt.imshow(patsy.dmatrix("C(group, Sum) * C(language, Sum)", df_2way), aspect='auto'))
```
___
# 2-way Repeated measures ANOVA in Python (within-subject factors)
___
Let's look at a different design, where we have repeated measures for each subject, which is common in psychological experiments. In this case we need to include random effects for each subject. We can conduct an ANOVA on such a design this using `mixedlm`. In the examples here, we are modeling a random intercept for each subject, but by passing the 're_formula' option, we can also include a random slope for each subject. If we only have a within-subject design, we can also use the `AnovaRM` function in Python, however, only fully balanced within-subject designs are supported here. One general limitation for the Python implementations is that *crossed random-effects are not supported*, so we can only specify one factor to model the random effects.

In the example below, I'm simulating data from a single-group design with two factors: All subjects performed three different tasks before and after a treatment. Note that in the data simulation, I'm introducing the factor sub_id which is unique for each subject and differs from the subject ID that we defined in the folder system (in combination with the 'group' string, the subject ID gives a unique identifier within the BIDS folder format).
```
# information on experimental design
subs_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']
task_list = ['task1', 'task2', 'task3']
condition_list = ['pre', 'post']

# read data into dataframe
df_2way_rm = pd.DataFrame(columns=["sub_id", "task", "condition", "my_value"])
my_row = 0
# unique subject-ID as additional factor
sub_id = 0
for sub in subs_list:
    sub_id = sub_id + 1
    for ind_t, task in enumerate(task_list):
        for ind_c, con in enumerate(condition_list):
            # generate random value here as example
            my_val = np.random.normal(ind_t + ind_c, 1, 1)[0]
            df_2way_rm.loc[my_row] = [sub_id, task, con, my_val]
            my_row = my_row + 1

# conduct ANOVA using mixedlm
my_model_fit = smf.mixedlm("my_value ~ task * condition", df_2way_rm, groups=df_2way_rm["sub_id"]).fit()
# get fixed effects
my_model_fit.summary()
# get random effects
my_model_fit.random_effects

# conduct ANOVA using AnovaRM
my_model_fit = AnovaRM(df_2way_rm, 'my_value', 'sub_id', within=['task', 'condition']).fit()
print(my_model_fit.anova_table)
```
___
# 4-way ANOVA with between-group and within-group factors (repeated measures)
___
If we wanted to conduct a mixed-model ANOVA that includes between-subject factors (group and language) and within-subject factors (task and condition), can do this using the `mixedlm` function, similar as shown above:
```
group_list = ['control','patient1','patient2']
language_list = ['English', 'German', 'French']
subs_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']
task_list = ['task1', 'task2', 'task3']
condition_list = ['pre', 'post']

# read data into dataframe
df_full = pd.DataFrame(columns=["group", "language", "sub_id", "task", "condition", "my_value"])
my_row = 0
# unique subject-ID
sub_id = 0
for ind_g, group in enumerate(group_list):
    for ind_l, lan in enumerate(language_list):
        for sub in subs_list:
            sub_id = sub_id + 1
            for ind_t, task in enumerate(task_list):
                for ind_c, con in enumerate(condition_list):
                    # generate random value here as example
                    my_val = np.random.normal(ind_c + ind_t, 1, 1)[0]
                    df_full.loc[my_row] = [group, lan, sub_id, task, con, my_val]
                    my_row = my_row + 1

# conduct ANOVA using mixedlm
my_model_fit = smf.mixedlm("my_value ~ group * language * condition", df_full, groups=df_full["sub_id"]).fit().summary()
# get fixed effects
my_model_fit.summary()
# get random effects
my_model_fit.random_effects
```
# Move from Python to R
As demonstrated above, most linear models can be succesfully be implemented in Python. The only limitation is that crossed-random effects are not supported. If this is needed, or for other reasons, we might want to run our analysis in R instead. An easy way to convert between both frameworks by writing out the dataframe to csv-format, which can be read by both Python and R. Here, we the data for two of the ANOVAs that we conducted above, to demonstrate that the results in R are exactly the same.
```
df_2way.to_csv('df_2way.csv', index=False)
df_full.to_csv('df_full.csv', index=False)
```
___
# 2-way ANOVA in R (between-subject factors)
___
We will start with the 2-way between-subjects ANOVA, which can be conducted with the R package `lm`. We can also access the underlying model matrix and inspect it to verify that the same model is applied in both Python and R. Similar as in Patsy, we can also change the coding scheme for the categorical factors.
```
# ! R code now, not Python!

library(readr)

# read in data from 2-way ANOVA with between-subject factors
df_2way <- read_csv("df_2way.csv")
# fit linear model and get parameter estimates
model_fit <- lm(my_value ~ group * condition, df)
# display anova table
anova(model_fit)
# display results of linear regression
summary(model_fit)

# access underlying model
my_glm = model.matrix(model_fit)
# inspect GLM
image(t(my_glm))

# change coding scheme
model_fit <- lm(my_value ~ group * condition, df, contrasts = list(group = "contr.sum", condition = "contr.sum"))

```
___
# 4-way ANOVA in R (between-subject and within-subject factors)
___
In a very similar fashion, we can perform an ANOVA that includes within-subject factors and random effects. In this case we use the `lme4` package.
```
library(lme4)
library(lmerTest)

# read in data from 4-way ANOVA with between-subject and within-subject factors
df_full <- read_csv("df_full.csv")

# get parameter estimates from a linear regression with random effects
my_model_fit <- lmer(my_value ~ group * language * task * condition + (1|sub_id), df_full)
# display results of linear regression
summary(my_model_fit)
# main and interaction effects
anova(my_model_fit)
# random effects
rand(my_model_fit)

# access underlying model for fixed effects
my_glm_fe = model.matrix(my_model_fit)
# access underlying model for random effects
my_glm_re = getME(my_model_fit, "Zt")
# inspect matrices
image(t(my_glm_fe))
image(t(my_glm_re))
```

# That's it!
As concluding remark, I would like to encourage you to build the model matrix for your ANOVA by hand and to compare it to the automatic matrix generation in Patsy using different coding schemes. General linear models are a powerful statistical tool that is widely used in psychological and neuroimaging data analysis, so it's worth wrapping your head around the underlying principles. Below, I post some links that I found useful when preparing this tutorial.

Thanks for reading this post :-)

Nicole

### Useful links:
* Coding schemes for categorical factors:  
https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/
* Python vs. R:  
https://medium.com/@data_driven/python-vs-r-for-data-science-and-the-winner-is-3ebb1a968197
* Repeated-measures ANOVA in Python:  
https://www.marsja.se/repeated-measures-anova-using-python/
* Statsmodels mixedlm and lme4:
https://www.statsmodels.org/stable/examples/notebooks/generated/mixed_lm_example.html
